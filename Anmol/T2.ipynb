{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44833583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE PERFORMANCE\n",
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9861111111111112\n",
      "Recall: 0.9861111111111112\n",
      "ROC-AUC: 0.9953703703703703\n"
     ]
    }
   ],
   "source": [
    "#BASELINE MODEL (NO FEATURE ENGINEERING)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "baseline_model = LogisticRegression(max_iter=500)\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_base = baseline_model.predict(X_test_scaled)\n",
    "y_prob_base = baseline_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"BASELINE PERFORMANCE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_base))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_base))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e302d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE ENGINNERING\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[\"radius_perimeter_ratio\"] = df[\"mean radius\"] / df[\"mean perimeter\"]\n",
    "    df[\"area_radius_ratio\"] = df[\"mean area\"] / (df[\"mean radius\"] ** 2)\n",
    "    df[\"texture_smoothness_interaction\"] = df[\"mean texture\"] * df[\"mean smoothness\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_train_fe = engineer_features(X_train)\n",
    "X_test_fe = engineer_features(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER FEATURE ENGINEERING\n",
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9861111111111112\n",
      "Recall: 0.9861111111111112\n",
      "ROC-AUC: 0.996031746031746\n"
     ]
    }
   ],
   "source": [
    "#REATRAING MODEL WITH NEW FEATURES\n",
    "scaler_fe = StandardScaler()\n",
    "X_train_fe_scaled = scaler_fe.fit_transform(X_train_fe)\n",
    "X_test_fe_scaled = scaler_fe.transform(X_test_fe)\n",
    "\n",
    "fe_model = LogisticRegression(max_iter=500)\n",
    "fe_model.fit(X_train_fe_scaled, y_train)\n",
    "\n",
    "y_pred_fe = fe_model.predict(X_test_fe_scaled)\n",
    "y_prob_fe = fe_model.predict_proba(X_test_fe_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nAFTER FEATURE ENGINEERING\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_fe))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_fe))\n",
    "print(\"Recall:\", recall_score(y_test, y_prob_fe > 0.5))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_fe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99519c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric  Baseline  After Feature Eng\n",
      "0   Accuracy  0.982456           0.982456\n",
      "1  Precision  0.986111           0.986111\n",
      "2     Recall  0.986111           0.986111\n",
      "3    ROC-AUC  0.995370           0.996032\n"
     ]
    }
   ],
   "source": [
    "#COMPARING RESULTS\n",
    "results = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"ROC-AUC\"],\n",
    "    \"Baseline\": [\n",
    "        accuracy_score(y_test, y_pred_base),\n",
    "        precision_score(y_test, y_pred_base),\n",
    "        recall_score(y_test, y_pred_base),\n",
    "        roc_auc_score(y_test, y_prob_base)\n",
    "    ],\n",
    "    \"After Feature Eng\": [\n",
    "        accuracy_score(y_test, y_pred_fe),\n",
    "        precision_score(y_test, y_pred_fe),\n",
    "        recall_score(y_test, y_pred_fe),\n",
    "        roc_auc_score(y_test, y_prob_fe)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
